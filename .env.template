# AI Configuration
# For production: Use OpenAI
OPENAI_API_KEY=your_openai_api_key_here

# For development: Use local Ollama
ENVIRONMENT=dev  # Set to 'dev' to use Ollama, 'prod' for OpenAI
OLLAMA_HOST=http://localhost:11434  # Ollama API endpoint
OLLAMA_MODEL=qwen2.5-coder  # Model to use with Ollama

# Optional: LangChain configuration (for future use)
LANGCHAIN_API_KEY=your_langchain_api_key_here

# Optional: Analysis preferences
ANALYSIS_VERBOSE=true
ANALYSIS_TIMEOUT=300  # seconds
