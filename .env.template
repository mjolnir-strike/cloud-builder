# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Alternative Models
# OLLAMA_MODEL=gpt-4-0-mini  # For GPT-4-0-mini
# OLLAMA_MODEL=llama3.2      # For Llama 3.2
